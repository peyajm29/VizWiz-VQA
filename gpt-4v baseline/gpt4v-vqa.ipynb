{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=\"sk-proj-1lBbtEgG5PP9cZclbDJLT3BlbkFJnDh3qBqBZBaehUxo4CxU\")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4-turbo\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\"type\": \"text\", \"text\": \"What color is this candle?\"},\n",
    "        {\n",
    "          \"type\": \"image_url\",\n",
    "          \"image_url\": {\n",
    "            \"url\": \"https://vizwiz.cs.colorado.edu/VizWiz_visualization_img/VizWiz_train_00009236.jpg\",\n",
    "          },\n",
    "        },\n",
    "      ],\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"text\", \"text\": \"You are a crowdsource worker answering visual questions from blind people. The answers will mostly be yes/no, number, unanswerable or other. If it is unanswerable, reply unanswerable.\"},\n",
    "            {\"type\": \"text\", \"text\": \"response example: creamy\"},\n",
    "            {\"type\": \"text\", \"text\": \"response example: unanswerable\"},\n",
    "            {\"type\": \"text\", \"text\": \"response example: stop reset start\"},\n",
    "            {\"type\": \"text\", \"text\": \"response example: computer mouse\"},\n",
    "            {\"type\": \"text\", \"text\": \"response example: raisin date walnut\"},\n",
    "            {\"type\": \"text\", \"text\": \"response example: sticker\"},\n",
    "            {\"type\": \"text\", \"text\": \"response example: yes\"},\n",
    "            {\"type\": \"text\", \"text\": \"response example: eight\"},\n",
    "            {\"type\": \"text\", \"text\": \"response example: no\"},\n",
    "            {\"type\": \"text\", \"text\": \"response example: two\"},\n",
    "            {\"type\": \"text\", \"text\": \"response example: sloppy joe seasoning\"},\n",
    "            {\"type\": \"text\", \"text\": \"response example: unsuitable\"},\n",
    "            {\"type\": \"text\", \"text\": \"response example: blue\"},\n",
    "            {\"type\": \"text\", \"text\": \"response example: moutain dew code red\"},\n",
    "            {\"type\": \"text\", \"text\": \"response example: you going to bed\"},\n",
    "            {\"type\": \"text\", \"text\": \"response example: coconut body butter\"},\n",
    "            {\"type\": \"text\", \"text\": \"response example: i do not see anything on this side tin perhaps something on bottom\"},\n",
    "            {\"type\": \"text\", \"text\": \"response example: on table\"},\n",
    "            {\"type\": \"text\", \"text\": \"response example: living room\"},\n",
    "            {\"type\": \"text\", \"text\": \"response example: no pumpkin spice coffee\"},\n",
    "            {\"type\": \"text\", \"text\": \"response example: i dont know\"},\n",
    "            {\"type\": \"text\", \"text\": \"response example: chicken pasta\"},\n",
    "            {\"type\": \"text\", \"text\": \"response example: frog sitting on pottery dish\"},\n",
    "            {\"type\": \"text\", \"text\": \"response example: shelf has trading cards\"},\n",
    "            {\"type\": \"text\", \"text\": \"response example: unanswerable\"},\n",
    "            {\"type\": \"text\", \"text\": \"response example: food\"},\n",
    "            {\"type\": \"text\", \"text\": \"response example: nothing\"},\n",
    "            {\"type\": \"text\", \"text\": \"response example: easy go\"},\n",
    "            {\"type\": \"text\", \"text\": \"response example: sedan\"},\n",
    "            {\"type\": \"text\", \"text\": \"response example: nutrition facts\"},\n",
    "            {\"type\": \"text\", \"text\": \"response example: close to 10 inches\"},\n",
    "            {\"type\": \"text\", \"text\": \"response example: description membership benefits\"},\n",
    "            {\"type\": \"text\", \"text\": \"response example: solar garden light\"},\n",
    "            {\"type\": \"text\", \"text\": \"response example: orange\"},\n",
    "            {\"type\": \"text\", \"text\": \"response example: basil leaves\"},\n",
    "            {\"type\": \"text\", \"text\": \"response example: advanced antiseptic mouthwash tartar protection citrus flavor\"},\n",
    "            {\"type\": \"text\", \"text\": \"response example: remote control\"},\n",
    "            {\"type\": \"text\", \"text\": \"response example: grand theft auto vice city\"},\n",
    "            {\"type\": \"text\", \"text\": \"response example: apple pie spice\"},\n",
    "            {\"type\": \"text\", \"text\": \"response example: sweet sour chicken\"},\n",
    "            {\"type\": \"text\", \"text\": \"response example: action figure\"},\n",
    "            {\"type\": \"text\", \"text\": \"response example: incredible hulk\"},\n",
    "            {\"type\": \"text\", \"text\": \"response example: winney pooh stuff doll\"},\n",
    "            {\"type\": \"text\", \"text\": \"response example: minute made coolers lemon\"},\n",
    "            {\"type\": \"text\", \"text\": \"response example: books bookshelf pictures\"},\n",
    "            {\"type\": \"text\", \"text\": \"response example: right leg\"},\n",
    "            {\"type\": \"text\", \"text\": \"response example: coffee maker\"},\n",
    "            {\"type\": \"text\", \"text\": \"response example: yellow coffee mug\"},\n",
    "            {\"type\": \"text\", \"text\": \"response example: golden sweet whole kernel corn\"},\n",
    "            {\"type\": \"text\", \"text\": \"response example: pepsi\"}\n",
    "        ]\n",
    "    }\n",
    "  ],\n",
    "  max_tokens=30,\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=\"sk-proj-1lBbtEgG5PP9cZclbDJLT3BlbkFJnDh3qBqBZBaehUxo4CxU\")\n",
    "\n",
    "system_prompt = [\n",
    "            {\"type\": \"text\", \"text\": \"You are a crowdsource worker answering visual questions from blind people. The answers will mostly be yes/no, number, unanswerable or other. If it is unanswerable, reply unanswerable. Reply in only 1-3 keywords. Remove any descriptors, be specific.\"},\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "data_file = \"/Users/peyamowar/Downloads/Annotations/train.json\"\n",
    "with open(data_file, 'r') as file:\n",
    "    parsed_data = json.load(file)\n",
    "\n",
    "base_url = \"https://vizwiz.cs.colorado.edu/VizWiz_visualization_img/\"\n",
    "\n",
    "results = []\n",
    "i = 130\n",
    "\n",
    "for item in parsed_data[130:500]:\n",
    "    print(i)\n",
    "    i += 1\n",
    "    message = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": item[\"question\"]},\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": base_url + item[\"image\"]}},\n",
    "            ],\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": system_prompt\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4-turbo\",\n",
    "        messages=message,\n",
    "        max_tokens=30\n",
    "    )\n",
    "    \n",
    "    answer = response.choices[0].message.content\n",
    "\n",
    "    result = {\n",
    "        \"image\": item[\"image\"],\n",
    "        \"answer\": answer\n",
    "    }\n",
    "\n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_path = \"/Users/peyamowar/Downloads/Annotations/results-train-3.json\"\n",
    "\n",
    "with open(output_file_path, 'w') as output_file:\n",
    "    json.dump(results, output_file, indent = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 57.60%\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "with open('/Users/peyamowar/Downloads/Annotations/train.json') as f:\n",
    "    train_data = json.load(f)\n",
    "\n",
    "with open('/Users/peyamowar/Downloads/Annotations/results-train-2.json') as f:\n",
    "    results_data = json.load(f)\n",
    "\n",
    "results_dict = {item['image']: item['answer'] for item in results_data}\n",
    "\n",
    "contractions = {\"aint\": \"ain't\", \"arent\": \"aren't\", \"cant\": \"can't\", \"couldve\": \"could've\", \"couldnt\": \"couldn't\", \\\n",
    "\t\t\t\t\t\t\t \"couldn'tve\": \"couldn’t’ve\", \"couldnt’ve\": \"couldn’t’ve\", \"didnt\": \"didn’t\", \"doesnt\": \"doesn’t\", \"dont\": \"don’t\", \"hadnt\": \"hadn’t\", \\\n",
    "\t\t\t\t\t\t\t \"hadnt’ve\": \"hadn’t’ve\", \"hadn'tve\": \"hadn’t’ve\", \"hasnt\": \"hasn’t\", \"havent\": \"haven’t\", \"hed\": \"he’d\", \"hed’ve\": \"he’d’ve\", \\\n",
    "\t\t\t\t\t\t\t \"he’dve\": \"he’d’ve\", \"hes\": \"he’s\", \"howd\": \"how’d\", \"howll\": \"how’ll\", \"hows\": \"how’s\", \"Id’ve\": \"I’d’ve\", \"I’dve\": \"I’d’ve\", \\\n",
    "\t\t\t\t\t\t\t \"Im\": \"I’m\", \"Ive\": \"I’ve\", \"isnt\": \"isn’t\", \"itd\": \"it’d\", \"itd’ve\": \"it’d’ve\", \"it’dve\": \"it’d’ve\", \"itll\": \"it’ll\", \"let’s\": \"let’s\", \\\n",
    "\t\t\t\t\t\t\t \"maam\": \"ma’am\", \"mightnt\": \"mightn’t\", \"mightnt’ve\": \"mightn’t’ve\", \"mightn’tve\": \"mightn’t’ve\", \"mightve\": \"might’ve\", \\\n",
    "\t\t\t\t\t\t\t \"mustnt\": \"mustn’t\", \"mustve\": \"must’ve\", \"neednt\": \"needn’t\", \"notve\": \"not’ve\", \"oclock\": \"o’clock\", \"oughtnt\": \"oughtn’t\", \\\n",
    "\t\t\t\t\t\t\t \"ow’s’at\": \"’ow’s’at\", \"’ows’at\": \"’ow’s’at\", \"’ow’sat\": \"’ow’s’at\", \"shant\": \"shan’t\", \"shed’ve\": \"she’d’ve\", \"she’dve\": \"she’d’ve\", \\\n",
    "\t\t\t\t\t\t\t \"she’s\": \"she’s\", \"shouldve\": \"should’ve\", \"shouldnt\": \"shouldn’t\", \"shouldnt’ve\": \"shouldn’t’ve\", \"shouldn’tve\": \"shouldn’t’ve\", \\\n",
    "\t\t\t\t\t\t\t \"somebody’d\": \"somebodyd\", \"somebodyd’ve\": \"somebody’d’ve\", \"somebody’dve\": \"somebody’d’ve\", \"somebodyll\": \"somebody’ll\", \\\n",
    "\t\t\t\t\t\t\t \"somebodys\": \"somebody’s\", \"someoned\": \"someone’d\", \"someoned’ve\": \"someone’d’ve\", \"someone’dve\": \"someone’d’ve\", \\\n",
    "\t\t\t\t\t\t\t \"someonell\": \"someone’ll\", \"someones\": \"someone’s\", \"somethingd\": \"something’d\", \"somethingd’ve\": \"something’d’ve\", \\\n",
    "\t\t\t\t\t\t\t \"something’dve\": \"something’d’ve\", \"somethingll\": \"something’ll\", \"thats\": \"that’s\", \"thered\": \"there’d\", \"thered’ve\": \"there’d’ve\", \\\n",
    "\t\t\t\t\t\t\t \"there’dve\": \"there’d’ve\", \"therere\": \"there’re\", \"theres\": \"there’s\", \"theyd\": \"they’d\", \"theyd’ve\": \"they’d’ve\", \\\n",
    "\t\t\t\t\t\t\t \"they’dve\": \"they’d’ve\", \"theyll\": \"they’ll\", \"theyre\": \"they’re\", \"theyve\": \"they’ve\", \"twas\": \"’twas\", \"wasnt\": \"wasn’t\", \\\n",
    "\t\t\t\t\t\t\t \"wed’ve\": \"we’d’ve\", \"we’dve\": \"we’d’ve\", \"weve\": \"we've\", \"werent\": \"weren’t\", \"whatll\": \"what’ll\", \"whatre\": \"what’re\", \\\n",
    "\t\t\t\t\t\t\t \"whats\": \"what’s\", \"whatve\": \"what’ve\", \"whens\": \"when’s\", \"whered\": \"where’d\", \"wheres\": \"where's\", \"whereve\": \"where’ve\", \\\n",
    "\t\t\t\t\t\t\t \"whod\": \"who’d\", \"whod’ve\": \"who’d’ve\", \"who’dve\": \"who’d’ve\", \"wholl\": \"who’ll\", \"whos\": \"who’s\", \"whove\": \"who've\", \"whyll\": \"why’ll\", \\\n",
    "\t\t\t\t\t\t\t \"whyre\": \"why’re\", \"whys\": \"why’s\", \"wont\": \"won’t\", \"wouldve\": \"would’ve\", \"wouldnt\": \"wouldn’t\", \"wouldnt’ve\": \"wouldn’t’ve\", \\\n",
    "\t\t\t\t\t\t\t \"wouldn’tve\": \"wouldn’t’ve\", \"yall\": \"y’all\", \"yall’ll\": \"y’all’ll\", \"y’allll\": \"y’all’ll\", \"yall’d’ve\": \"y’all’d’ve\", \\\n",
    "\t\t\t\t\t\t\t \"y’alld’ve\": \"y’all’d’ve\", \"y’all’dve\": \"y’all’d’ve\", \"youd\": \"you’d\", \"youd’ve\": \"you’d’ve\", \"you’dve\": \"you’d’ve\", \\\n",
    "\t\t\t\t\t\t\t \"youll\": \"you’ll\", \"youre\": \"you’re\", \"youve\": \"you’ve\"}\n",
    "manualMap    = { 'none': '0',\n",
    "\t\t\t\t\t\t\t  'zero': '0',\n",
    "\t\t\t\t\t\t\t  'one': '1',\n",
    "\t\t\t\t\t\t\t  'two': '2',\n",
    "\t\t\t\t\t\t\t  'three': '3',\n",
    "\t\t\t\t\t\t\t  'four': '4',\n",
    "\t\t\t\t\t\t\t  'five': '5',\n",
    "\t\t\t\t\t\t\t  'six': '6',\n",
    "\t\t\t\t\t\t\t  'seven': '7',\n",
    "\t\t\t\t\t\t\t  'eight': '8',\n",
    "\t\t\t\t\t\t\t  'nine': '9',\n",
    "\t\t\t\t\t\t\t  'ten': '10'\n",
    "\t\t\t\t\t\t\t}\n",
    "articles     = ['a',\n",
    "\t\t\t\t\t\t\t 'an',\n",
    "\t\t\t\t\t\t\t 'the'\n",
    "\t\t\t\t\t\t\t]\n",
    " \n",
    "\n",
    "periodStrip  = re.compile(\"(?!<=\\d)(\\.)(?!\\d)\")\n",
    "commaStrip   = re.compile(\"(\\d)(\\,)(\\d)\")\n",
    "punct        = [';', r\"/\", '[', ']', '\"', '{', '}',\n",
    "\t\t\t\t\t\t\t '(', ')', '=', '+', '\\\\', '_', '-',\n",
    "\t\t\t\t\t\t\t '>', '<', '@', '`', ',', '?', '!']\n",
    "\n",
    "def process_text(text):\n",
    "    import re\n",
    "    punctuations = r\"[!\\\"#$%&'()*+,-./:;<=>?@[\\\\]^_`{|}~]\"\n",
    "    text = re.sub(punctuations, \" \", text.lower())\n",
    "    return re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "def processPunctuation(inText):\n",
    "\t\toutText = inText\n",
    "\t\tfor p in punct:\n",
    "\t\t\tif (p + ' ' in inText or ' ' + p in inText) or (re.search(commaStrip, inText) != None):\n",
    "\t\t\t\toutText = outText.replace(p, '')\n",
    "\t\t\telse:\n",
    "\t\t\t\toutText = outText.replace(p, ' ')\t\n",
    "\t\toutText = periodStrip.sub(\"\",\n",
    "\t\t\t\t\t\t\t\t\t  outText,\n",
    "\t\t\t\t\t\t\t\t\t  re.UNICODE)\n",
    "\t\treturn outText\n",
    "\t\n",
    "def processDigitArticle(inText):\n",
    "    outText = []\n",
    "    tempText = inText.lower().split()\n",
    "    for word in tempText:\n",
    "        word = manualMap.setdefault(word, word)\n",
    "        if word not in articles:\n",
    "            outText.append(word)\n",
    "        else:\n",
    "            pass\n",
    "    for wordId, word in enumerate(outText):\n",
    "        if word in contractions: \n",
    "            outText[wordId] = contractions[word]\n",
    "    outText = ' '.join(outText)\n",
    "    return outText\n",
    "\n",
    "def evaluate_accuracy(train_data, results_dict):\n",
    "    accuracies = []\n",
    "    for item in train_data:\n",
    "        image_name = item['image']\n",
    "        human_answers = [ans['answer'] for ans in item['answers']]\n",
    "        predicted_answer = results_dict.get(image_name)\n",
    "        \n",
    "        if predicted_answer is None:\n",
    "            continue \n",
    "\n",
    "        predicted_answer = predicted_answer.replace('\\n', ' ')\n",
    "        predicted_answer = predicted_answer.replace('\\t', ' ')\n",
    "        predicted_answer = predicted_answer.strip()\n",
    "        predicted_answer = processPunctuation(predicted_answer)\n",
    "        predicted_answer = processDigitArticle(predicted_answer)\n",
    "        answer_counts = {}\n",
    "        \n",
    "        for ans in human_answers:\n",
    "            processed_ans = process_text(ans)\n",
    "            if processed_ans in answer_counts:\n",
    "                answer_counts[processed_ans] += 1\n",
    "            else:\n",
    "                answer_counts[processed_ans] = 1\n",
    "\n",
    "        max_match_count = answer_counts.get(predicted_answer, 0)\n",
    "        accuracy = min(1, max_match_count / 3)\n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "    return np.mean(accuracies)\n",
    "\n",
    "overall_accuracy = evaluate_accuracy(train_data, results_dict)\n",
    "print(f\"Overall Accuracy: {overall_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images answered for 'other': 80\n",
      "Number of images answered for 'yes/no': 10\n",
      "Number of images answered for 'unanswerable': 45\n",
      "Number of images answered for 'number': 1\n",
      "Overall Accuracy: 57.60%\n",
      "Accuracy for 'other': 42.50%\n",
      "Accuracy for 'yes/no': 63.33%\n",
      "Accuracy for 'unanswerable': 84.44%\n",
      "Accuracy for 'number': 0.00%\n"
     ]
    }
   ],
   "source": [
    "def evaluate_accuracy_by_type(train_data, results_dict):\n",
    "    accuracies = []\n",
    "    type_accuracies = {}\n",
    "\n",
    "    for item in train_data:\n",
    "        image_name = item['image']\n",
    "        question_type = item['answer_type']\n",
    "        human_answers = [ans['answer'] for ans in item['answers']]\n",
    "        predicted_answer = results_dict.get(image_name)\n",
    "        \n",
    "        if predicted_answer is None:\n",
    "            continue  # Skip if no prediction is available for the image\n",
    "\n",
    "        predicted_answer = process_text(predicted_answer)\n",
    "        predicted_answer = predicted_answer.replace('\\n', ' ')\n",
    "        predicted_answer = predicted_answer.replace('\\t', ' ')\n",
    "        predicted_answer = predicted_answer.strip()\n",
    "        predicted_answer = processPunctuation(predicted_answer)\n",
    "        predicted_answer = processDigitArticle(predicted_answer)\n",
    "        answer_counts = {}\n",
    "        \n",
    "        # Count how many times each answer appears\n",
    "        for ans in human_answers:\n",
    "            processed_ans = process_text(ans)\n",
    "            if processed_ans in answer_counts:\n",
    "                answer_counts[processed_ans] += 1\n",
    "            else:\n",
    "                answer_counts[processed_ans] = 1\n",
    "\n",
    "        # Calculate accuracy for this prediction\n",
    "        max_match_count = answer_counts.get(predicted_answer, 0)\n",
    "        accuracy = min(1, max_match_count / 3)\n",
    "        accuracies.append(accuracy)\n",
    "        \n",
    "        # Group accuracy by question type\n",
    "        if question_type not in type_accuracies:\n",
    "            type_accuracies[question_type] = []\n",
    "        type_accuracies[question_type].append(accuracy)\n",
    "\n",
    "    # Return the overall accuracy and accuracies by type\n",
    "    overall_accuracy = np.mean(accuracies)\n",
    "    type_accuracy_means = {k: np.mean(v) for k, v in type_accuracies.items()}\n",
    "    return overall_accuracy, type_accuracy_means\n",
    "\n",
    "answered_count_by_type = {}\n",
    "question_types = {item['image']: item['answer_type'] for item in train_data}\n",
    "\n",
    "for image_name in results_dict.keys():\n",
    "    if image_name in question_types:\n",
    "        q_type = question_types[image_name]\n",
    "        if q_type in answered_count_by_type:\n",
    "            answered_count_by_type[q_type] += 1\n",
    "        else:\n",
    "            answered_count_by_type[q_type] = 1\n",
    "\n",
    "# Print the counts\n",
    "for q_type, count in answered_count_by_type.items():\n",
    "    print(f\"Number of images answered for '{q_type}': {count}\")\n",
    "\n",
    "# Run evaluation\n",
    "overall_accuracy, type_accuracy_means = evaluate_accuracy_by_type(train_data, results_dict)\n",
    "print(f\"Overall Accuracy: {overall_accuracy * 100:.2f}%\")\n",
    "for q_type, acc in type_accuracy_means.items():\n",
    "    print(f\"Accuracy for '{q_type}': {acc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "data_file = \"/Users/peyamowar/Downloads/Annotations/test.json\"\n",
    "with open(data_file, 'r') as file:\n",
    "    parsed_data = json.load(file)\n",
    "\n",
    "base_url = \"https://vizwiz.cs.colorado.edu/VizWiz_visualization_img/\"\n",
    "\n",
    "import requests\n",
    "\n",
    "def is_image_url(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            content_type = response.headers['Content-Type']\n",
    "            return 'image' in content_type\n",
    "        else:\n",
    "            return False\n",
    "    except requests.RequestException as e:\n",
    "        return False\n",
    "\n",
    "results = []\n",
    "i = 1\n",
    "\n",
    "for item in parsed_data[130:500]:\n",
    "    print(i)\n",
    "    i += 1\n",
    "    if not is_image_url(base_url + item[\"image\"]):\n",
    "        continue\n",
    "\n",
    "    if i > 200:\n",
    "        break\n",
    "\n",
    "    message = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": item[\"question\"]},\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": base_url + item[\"image\"]}},\n",
    "            ],\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": system_prompt\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4-turbo\",\n",
    "        messages=message,\n",
    "        max_tokens=30\n",
    "    )\n",
    "    \n",
    "    answer = response.choices[0].message.content\n",
    "\n",
    "    result = {\n",
    "        \"image\": item[\"image\"],\n",
    "        \"answer\": answer\n",
    "    }\n",
    "\n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
